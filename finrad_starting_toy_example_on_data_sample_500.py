# -*- coding: utf-8 -*-
"""FinRAD_starting_toy_example_on_data_sample_500.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CB6MxgVQyTPXJf5tldTbDV8sBkYklxfn
"""

from sklearn.metrics import roc_auc_score

import pickle

import pandas as pd

from sklearn.model_selection import train_test_split

data = pd.read_csv('data_sample_500.csv')
data

data['assigned_readibility'].value_counts(normalize = True)

data['assigned_readibility'].value_counts()

data[data['assigned_readibility']==1]['difficult_words'].mean()

data[data['assigned_readibility']==1]['difficult_words'].median()

data[data['assigned_readibility']==1]['difficult_words'].mode()

data[data['assigned_readibility']==0]['difficult_words'].mean()

data[data['assigned_readibility']==0]['difficult_words'].median()

data[data['assigned_readibility']==0]['difficult_words'].mode()

data[['source', 'assigned_readibility']].value_counts().reset_index()

data.columns

numeric_columns = ['assigned_readibility',
       'flesch_reading_ease', 'flesch_kincaid_grade', 'smog_index',
       'coleman_liau_index', 'automated_readability_index',
       'dale_chall_readability_score', 'difficult_words',
       'linsear_write_formula', 'gunning_fog',
       'fernandez_huerta', 'szigriszt_pazos', 'gutierrez_polini', 'crawford',
       'gulpease_index', 'osman']

pearson_corr = data[numeric_columns].corr(method='pearson')
pearson_corr

kendall_corr = data[numeric_columns].corr(method='kendall')
kendall_corr

spearman_corr = data[numeric_columns].corr(method='spearman')
spearman_corr

#NON-LINEAR CORRELATION
#phik
#mic (packge minepy) - maximal information

!pip install phik

import phik
from phik import resources, report

data[numeric_columns].phik_matrix()

data[numeric_columns].global_phik()

data[numeric_columns].significance_matrix()

list(data[data['assigned_readibility']==0]['definitions'].sample(2))

report.correlation_report(data[numeric_columns], pdf_file_name='phik_correlation_report.pdf')

!pip install minepy

from minepy import MINE
mine = MINE()
for col in ['flesch_reading_ease', 'flesch_kincaid_grade', 'smog_index',
       'coleman_liau_index', 'automated_readability_index',
       'dale_chall_readability_score', 'difficult_words',
       'linsear_write_formula', 'gunning_fog',
       'fernandez_huerta', 'szigriszt_pazos', 'gutierrez_polini', 'crawford',
       'gulpease_index', 'osman']:
  mine.compute_score(data[col].values, data['assigned_readibility'].values)
  print(col,mine.mic())

for col in numeric_columns:
  auroc = roc_auc_score(data['assigned_readibility'].values, data[col].values)
  print(col,auroc,"\n")

features = ['definitions']
Y = data['assigned_readibility']

import numpy as np
np.random.seed(0)
msk = np.random.rand(len(data)) < 0.8
df = data[msk]
df = df.reset_index().copy()
val_df = data[~msk]
val_df = val_df.reset_index().copy()

for col in numeric_columns:
  auroc = roc_auc_score(val_df['assigned_readibility'].values, val_df[col].values)
  print(col,auroc,"\n")

"""# Feature extraction: TF-IDF"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

tfidf_model_original = TfidfVectorizer(
    ngram_range=(1, 4), min_df=0.0005, stop_words="english"
)

tfidf_model_original.fit(df["definitions"])

tfidf_df_train_original = pd.DataFrame(
    tfidf_model_original.transform(df["definitions"]).todense()
)
tfidf_df_train_original.columns = sorted(tfidf_model_original.vocabulary_)

# validation
tfidf_df_valid_original = pd.DataFrame(
    tfidf_model_original.transform(val_df["definitions"]).todense()
)
tfidf_df_valid_original.columns = sorted(tfidf_model_original.vocabulary_)

tfidf_df_train_original

tfidf_df_valid_original

"""# Logistic Regression Model"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score

train_X = tfidf_df_train_original
train_y = df['assigned_readibility']
valid_X = tfidf_df_valid_original
valid_y = val_df['assigned_readibility']

def model(clf, train_X, train_y, valid_X, valid_y):
    clf.fit(train_X, train_y)
    pred_tr = clf.predict(train_X)
    pred_valid = clf.predict(valid_X)
    pred_tr_prob = clf.predict_proba(train_X)[:,1]
    pred_valid_prob = clf.predict_proba(valid_X)[:,1]
    print("\nTraining F1:{}".format(f1_score(train_y, pred_tr, average="weighted")))
    print("Training Confusion Matrix \n{}".format(confusion_matrix(train_y, pred_tr)))
    print("Classification Report Train: \n{}".format(classification_report(train_y, pred_tr)))
    print("AUC Train", roc_auc_score(train_y, pred_tr_prob))

    print(
        "\nValidation F1:{}".format(f1_score(valid_y, pred_valid, average="weighted"))
    )
    print(
        "Validation Confusion Matrix \n{}".format(confusion_matrix(valid_y, pred_valid))
    )
    print(
        "Classification Report: \n{}".format(classification_report(valid_y, pred_valid))
    )
    print("AUC Valid", roc_auc_score(valid_y, pred_valid_prob))

lr_clf = LogisticRegression(solver="lbfgs", n_jobs=-1)
model(lr_clf, train_X, train_y, valid_X, valid_y)
params = lr_clf.get_params()
print(params)

pickle.dump(lr_clf, open("lr_clf.pickle","wb"))